#!/usr/bin/env python3
"""
æ™ºèƒ½ç®¡é“ç·¨æ’å™¨ - è™•ç†æ­¥é©Ÿé–“çš„ç›®éŒ„ä¾è³´é—œä¿‚
è§£æ±ºäººè‡‰åµæ¸¬å¾Œè£åˆ‡æ‡‰è©²å¾éæ¿¾çµæœè®€å–çš„å•é¡Œ
"""

import os
import logging
from typing import Optional, Dict, List
from services import (
    validator_service, 
    face_detection_service, 
    crop_service, 
    tag_service, 
    upscale_service, 
    lpips_clustering_service
)
from utils.file_utils import scan_directory_for_images
from utils.error_handler import safe_execute
from config import settings as default_settings

class PipelineOrchestrator:
    """
    æ™ºèƒ½ç®¡é“ç·¨æ’å™¨ - è™•ç†æ­¥é©Ÿé–“çš„ä¾è³´é—œä¿‚
    """
    
    def __init__(self, config=None, logger: Optional[logging.Logger] = None):
        self.config = config if config else default_settings
        
        if logger is None:
            self.logger = logging.getLogger(__name__)
            if not self.logger.handlers:
                handler = logging.StreamHandler()
                formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
                handler.setFormatter(formatter)
                self.logger.addHandler(handler)
                self.logger.setLevel(logging.INFO)
        else:
            self.logger = logger
        
        # æ­¥é©ŸåŸ·è¡Œé †åºå’Œä¾è³´é—œä¿‚
        self.step_order = ["validate", "face_detect", "cluster", "crop", "tag", "upscale"]
        
        # ç®¡é“ç‹€æ…‹ï¼šè¨˜éŒ„æ¯å€‹æ­¥é©Ÿçš„è¼¸å‡ºç›®éŒ„
        self.pipeline_state = {
            "current_input_dir": None,
            "step_outputs": {},
            "processing_stats": {
                "total_steps": 0,
                "completed_steps": 0,
                "failed_steps": 0,
                "step_details": {}
            }
        }


    def _determine_next_working_directory(self, completed_step: str, step_result: Dict, current_dir: str) -> str:
        """
        æ ¹æ“šå®Œæˆçš„æ­¥é©Ÿçµæœæ±ºå®šä¸‹ä¸€å€‹æ­¥é©Ÿçš„å·¥ä½œç›®éŒ„
        
        Args:
            completed_step: å‰›å®Œæˆçš„æ­¥é©Ÿåç¨±
            step_result: æ­¥é©ŸåŸ·è¡Œçµæœ
            current_dir: ç•¶å‰å·¥ä½œç›®éŒ„
            
        Returns:
            ä¸‹ä¸€å€‹æ­¥é©Ÿæ‡‰è©²ä½¿ç”¨çš„å·¥ä½œç›®éŒ„
        """
        # äººè‡‰åµæ¸¬æ­¥é©Ÿ - å¦‚æœæœ‰éæ¿¾ï¼Œä¸‹ä¸€æ­¥ä½¿ç”¨è¨“ç·´ç›®éŒ„
        if completed_step == "face_detect":
            if step_result.get("filter_applied", False) and step_result.get("training_directory"):
                training_dir = step_result["training_directory"]
                if os.path.exists(training_dir):
                    self.logger.info(f"[PipelineOrchestrator] äººè‡‰éæ¿¾å®Œæˆï¼Œå¾ŒçºŒæ­¥é©Ÿä½¿ç”¨è¨“ç·´ç›®éŒ„: {training_dir}")
                    return training_dir
        
        # èšé¡æ­¥é©Ÿ - é€šå¸¸åœ¨åŸç›®éŒ„é€²è¡Œï¼Œä½†å¯èƒ½å‰µå»ºå­ç›®éŒ„
        elif completed_step == "cluster":
            cluster_output = step_result.get("output_directory")
            if cluster_output and os.path.exists(cluster_output):
                return cluster_output
        
        # è£åˆ‡æ­¥é©Ÿ - ä½¿ç”¨è£åˆ‡è¼¸å‡ºç›®éŒ„
        elif completed_step == "crop":
            crop_output = step_result.get("output_directory")
            if crop_output and os.path.exists(crop_output):
                self.logger.info(f"[PipelineOrchestrator] è£åˆ‡å®Œæˆï¼Œå¾ŒçºŒæ­¥é©Ÿä½¿ç”¨è£åˆ‡ç›®éŒ„: {crop_output}")
                return crop_output
        
        # æ”¾å¤§æ­¥é©Ÿ - ä½¿ç”¨æ”¾å¤§è¼¸å‡ºç›®éŒ„  
        elif completed_step == "upscale":
            upscale_output = step_result.get("output_directory")
            if upscale_output and os.path.exists(upscale_output):
                self.logger.info(f"[PipelineOrchestrator] æ”¾å¤§å®Œæˆï¼Œå¾ŒçºŒæ­¥é©Ÿä½¿ç”¨æ”¾å¤§ç›®éŒ„: {upscale_output}")
                return upscale_output
        
        # é©—è­‰å’Œæ¨™è¨˜æ­¥é©Ÿé€šå¸¸ä¸æ”¹è®Šå·¥ä½œç›®éŒ„
        # å¦‚æœæ²’æœ‰ç‰¹æ®Šè¼¸å‡ºç›®éŒ„ï¼Œç¹¼çºŒä½¿ç”¨ç•¶å‰ç›®éŒ„
        return current_dir

    def _execute_validation_step(self, input_dir: str) -> Dict:
        """åŸ·è¡Œåœ–ç‰‡é©—è­‰æ­¥é©Ÿ"""
        self.logger.info(f"[PipelineOrchestrator] åŸ·è¡Œåœ–ç‰‡é©—è­‰: {input_dir}")
        
        try:
            is_valid, message, valid_paths = validator_service.validate_image_service(
                input_dir, self.logger, self.config, is_directory=True
            )
            
            result = {
                "success": is_valid,
                "message": message,
                "valid_count": len(valid_paths) if valid_paths else 0,
                "output_directory": input_dir  # é©—è­‰ä¸æ”¹è®Šç›®éŒ„
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"[PipelineOrchestrator] é©—è­‰æ­¥é©Ÿå¤±æ•—: {e}")
            return {"success": False, "message": f"é©—è­‰å¤±æ•—: {str(e)}"}

    def _execute_face_detection_step(self, input_dir: str) -> Dict:
        """åŸ·è¡Œäººè‡‰åµæ¸¬æ­¥é©Ÿ"""
        self.logger.info(f"[PipelineOrchestrator] åŸ·è¡Œäººè‡‰åµæ¸¬å’Œéæ¿¾: {input_dir}")
        
        try:
            # ä½¿ç”¨æ–°çš„è¨“ç·´å°å‘éæ¿¾åŠŸèƒ½
            success, summary, results = face_detection_service.filter_images_for_training(
                input_dir, self.logger, self.config
            )
            
            if success and results:
                # æª¢æŸ¥æ˜¯å¦æœ‰è¨“ç·´åœ–ç‰‡ç”¢ç”Ÿ
                training_count = results.get("filter_stats", {}).get("training_count", 0)
                training_dir = None
                
                if training_count > 0 and results.get("training_images"):
                    # ç²å–è¨“ç·´ç›®éŒ„
                    first_training_image = results["training_images"][0]
                    training_dir = os.path.dirname(first_training_image)
                
                result = {
                    "success": True,
                    "message": summary,
                    "training_directory": training_dir,
                    "training_count": training_count,
                    "excluded_count": results.get("filter_stats", {}).get("excluded_count", 0),
                    "face_distribution": results.get("face_distribution", {}),
                    "filter_applied": True,
                    "output_directory": training_dir  # å¾ŒçºŒæ­¥é©Ÿä½¿ç”¨è¨“ç·´ç›®éŒ„
                }
            else:
                result = {
                    "success": False,
                    "message": summary,
                    "filter_applied": False
                }
            
            return result
            
        except Exception as e:
            self.logger.error(f"[PipelineOrchestrator] äººè‡‰åµæ¸¬æ­¥é©Ÿå¤±æ•—: {e}")
            return {"success": False, "message": f"äººè‡‰åµæ¸¬å¤±æ•—: {str(e)}"}

    def _execute_crop_step(self, input_dir: str) -> Dict:
        """åŸ·è¡Œåœ–ç‰‡è£åˆ‡æ­¥é©Ÿ"""
        self.logger.info(f"[PipelineOrchestrator] åŸ·è¡Œåœ–ç‰‡è£åˆ‡: {input_dir}")
        
        try:
            # å‰µå»ºè£åˆ‡è¼¸å‡ºç›®éŒ„
            crop_output_dir = os.path.join(os.path.dirname(input_dir), "cropped_images")
            
            success, summary, results = crop_service.crop_batch_with_categorization(
                input_dir, crop_output_dir, self.logger, self.config
            )
            
            result = {
                "success": success,
                "message": summary,
                "output_directory": crop_output_dir,
                "crop_categories": results.get("crop_categories", {}),
                "successful_crops": results.get("successful_crops", 0),
                "failed_crops": results.get("failed_crops", 0)
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"[PipelineOrchestrator] è£åˆ‡æ­¥é©Ÿå¤±æ•—: {e}")
            return {"success": False, "message": f"è£åˆ‡å¤±æ•—: {str(e)}"}

    def _execute_clustering_step(self, input_dir: str) -> Dict:
        """åŸ·è¡ŒLPIPSèšé¡æ­¥é©Ÿ"""
        self.logger.info(f"[PipelineOrchestrator] åŸ·è¡ŒLPIPSèšé¡: {input_dir}")
        
        try:
            # æƒæåœ–ç‰‡æ–‡ä»¶
            image_files = scan_directory_for_images(input_dir, recursive=True)
            
            if not image_files:
                return {"success": False, "message": "æœªæ‰¾åˆ°åœ–ç‰‡æ–‡ä»¶é€²è¡Œèšé¡"}
            
            results, message = lpips_clustering_service.cluster_images_service_entry(
                image_files, self.logger, self.config
            )
            
            result = {
                "success": True,
                "message": message,
                "output_directory": input_dir,  # èšé¡æœƒä¿®æ”¹åŸç›®éŒ„çµæ§‹
                "cluster_results": results
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"[PipelineOrchestrator] èšé¡æ­¥é©Ÿå¤±æ•—: {e}")
            return {"success": False, "message": f"èšé¡å¤±æ•—: {str(e)}"}

    def _execute_tagging_step(self, input_dir: str) -> Dict:
        """åŸ·è¡Œåœ–ç‰‡æ¨™è¨˜æ­¥é©Ÿ"""
        self.logger.info(f"[PipelineOrchestrator] åŸ·è¡Œåœ–ç‰‡æ¨™è¨˜: {input_dir}")
        
        try:
            success, summary, results = tag_service.tag_batch_images(
                input_dir, self.logger, self.config
            )
            
            result = {
                "success": success,
                "message": summary,
                "output_directory": input_dir,  # æ¨™è¨˜ä¸æ”¹è®Šç›®éŒ„çµæ§‹
                "successful_tags": results.get("successful_tags", 0),
                "failed_tags": results.get("failed_tags", 0),
                "total_tags_generated": results.get("total_tags_generated", 0)
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"[PipelineOrchestrator] æ¨™è¨˜æ­¥é©Ÿå¤±æ•—: {e}")
            return {"success": False, "message": f"æ¨™è¨˜å¤±æ•—: {str(e)}"}

    def _execute_upscale_step(self, input_dir: str) -> Dict:
        """åŸ·è¡Œåœ–ç‰‡æ”¾å¤§æ­¥é©Ÿ"""
        self.logger.info(f"[PipelineOrchestrator] åŸ·è¡Œåœ–ç‰‡æ”¾å¤§: {input_dir}")
        
        try:
            # å‰µå»ºæ”¾å¤§è¼¸å‡ºç›®éŒ„
            upscale_output_dir = os.path.join(os.path.dirname(input_dir), "upscaled_images")
            
            success, summary, results = upscale_service.upscale_batch_images(
                input_dir, upscale_output_dir, self.logger, self.config
            )
            
            result = {
                "success": success,
                "message": summary,
                "output_directory": upscale_output_dir,
                "successful_upscales": results.get("successful_upscales", 0),
                "failed_upscales": results.get("failed_upscales", 0),
                "skipped_files": results.get("skipped_files", 0)
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"[PipelineOrchestrator] æ”¾å¤§æ­¥é©Ÿå¤±æ•—: {e}")
            return {"success": False, "message": f"æ”¾å¤§å¤±æ•—: {str(e)}"}

    def process_pipeline(self, input_directory: str, selected_steps: List[str] = None) -> Dict:
        """
        åŸ·è¡Œå®Œæ•´çš„æ‰¹é‡è™•ç†ç®¡é“ - æ­£ç¢ºçš„ç›®éŒ„ç´šåˆ¥æ­¥é©Ÿé †åºåŸ·è¡Œ
        
        æ‰¹é‡è™•ç†é‚è¼¯ï¼š
        1. æ­¥é©Ÿ1å®Œæˆæ•´å€‹ç›®éŒ„è™•ç† â†’ æ­¥é©Ÿ2è™•ç†æ­¥é©Ÿ1çš„è¼¸å‡ºç›®éŒ„ â†’ ...
        2. æ¯å€‹æ­¥é©Ÿè™•ç†å®Œæ•´å€‹ç›®éŒ„å¾Œæ‰é€²å…¥ä¸‹ä¸€å€‹æ­¥é©Ÿ
        3. å¾ŒçºŒæ­¥é©Ÿè‡ªå‹•ä½¿ç”¨å‰ä¸€æ­¥é©Ÿçš„è¼¸å‡ºç›®éŒ„ä½œç‚ºè¼¸å…¥
        
        Args:
            input_directory: åˆå§‹è¼¸å…¥ç›®éŒ„
            selected_steps: è¦åŸ·è¡Œçš„æ­¥é©Ÿåˆ—è¡¨
            
        Returns:
            è™•ç†çµæœå­—å…¸
        """
        if selected_steps is None:
            selected_steps = self.step_order
        
        self.logger.info(f"[PipelineOrchestrator] ğŸš€ é–‹å§‹æ‰¹é‡ç®¡é“è™•ç†")
        self.logger.info(f"[PipelineOrchestrator] ğŸ“ åˆå§‹è¼¸å…¥ç›®éŒ„: {input_directory}")
        self.logger.info(f"[PipelineOrchestrator] ğŸ”§ é¸å®šæ­¥é©Ÿ: {selected_steps}")
        self.logger.info(f"[PipelineOrchestrator] ğŸ“‹ æ‰¹é‡è™•ç†æ¨¡å¼: ç›®éŒ„ç´šåˆ¥æ­¥é©Ÿé †åºåŸ·è¡Œ")
        
        # é‡ç½®ç®¡é“ç‹€æ…‹
        self.pipeline_state = {
            "current_input_dir": input_directory,
            "step_outputs": {},
            "processing_stats": {
                "total_steps": len(selected_steps),
                "completed_steps": 0,
                "failed_steps": 0,
                "step_details": {}
            }
        }
        
        # æ­¥é©ŸåŸ·è¡Œå™¨æ˜ å°„
        step_executors = {
            "validate": self._execute_validation_step,
            "face_detect": self._execute_face_detection_step,
            "crop": self._execute_crop_step,
            "cluster": self._execute_clustering_step,
            "tag": self._execute_tagging_step,
            "upscale": self._execute_upscale_step
        }
        
        # ğŸ”„ æŒ‰é †åºåŸ·è¡Œæ­¥é©Ÿ - æ¯å€‹æ­¥é©Ÿå®Œæˆæ•´å€‹ç›®éŒ„è™•ç†
        current_working_dir = input_directory
        
        for step_name in self.step_order:
            if step_name in selected_steps:
                try:
                    self.logger.info(f"[PipelineOrchestrator] ğŸ”„ é–‹å§‹æ‰¹é‡åŸ·è¡Œæ­¥é©Ÿ: {step_name}")
                    self.logger.info(f"[PipelineOrchestrator] ğŸ“‚ ç•¶å‰å·¥ä½œç›®éŒ„: {current_working_dir}")
                    
                    # åŸ·è¡Œæ­¥é©Ÿ - è™•ç†æ•´å€‹ç›®éŒ„
                    executor = step_executors.get(step_name)
                    if executor:
                        step_result = executor(current_working_dir)
                        
                        # è¨˜éŒ„æ­¥é©Ÿçµæœ
                        self.pipeline_state["step_outputs"][step_name] = step_result
                        self.pipeline_state["processing_stats"]["step_details"][step_name] = step_result
                        
                        if step_result.get("success", False):
                            self.pipeline_state["processing_stats"]["completed_steps"] += 1
                            self.logger.info(f"[PipelineOrchestrator] âœ… æ­¥é©Ÿ {step_name} å®Œæˆ: {step_result.get('message', '')}")
                            
                            # ğŸ¯ æ›´æ–°ä¸‹ä¸€å€‹æ­¥é©Ÿçš„å·¥ä½œç›®éŒ„
                            next_working_dir = self._determine_next_working_directory(step_name, step_result, current_working_dir)
                            if next_working_dir != current_working_dir:
                                self.logger.info(f"[PipelineOrchestrator] ğŸ“‚ å·¥ä½œç›®éŒ„æ›´æ–°: {current_working_dir} â†’ {next_working_dir}")
                                current_working_dir = next_working_dir
                        else:
                            self.pipeline_state["processing_stats"]["failed_steps"] += 1
                            self.logger.error(f"[PipelineOrchestrator] âŒ æ­¥é©Ÿ {step_name} å¤±æ•—: {step_result.get('message', '')}")
                            # å¤±æ•—æ™‚ä¸æ›´æ–°å·¥ä½œç›®éŒ„ï¼Œå¾ŒçºŒæ­¥é©Ÿç¹¼çºŒä½¿ç”¨ç•¶å‰ç›®éŒ„
                    else:
                        self.logger.error(f"[PipelineOrchestrator] âŒ æœªçŸ¥æ­¥é©Ÿ: {step_name}")
                        self.pipeline_state["processing_stats"]["failed_steps"] += 1
                        
                except Exception as e:
                    self.pipeline_state["processing_stats"]["failed_steps"] += 1
                    self.logger.error(f"[PipelineOrchestrator] âŒ æ­¥é©Ÿ {step_name} åŸ·è¡Œç•°å¸¸: {e}")
        
        # ç”Ÿæˆæœ€çµ‚çµæœ
        stats = self.pipeline_state["processing_stats"]
        success_rate = (stats["completed_steps"] / stats["total_steps"]) * 100 if stats["total_steps"] > 0 else 0
        
        final_result = {
            "success": stats["failed_steps"] == 0,
            "message": f"æ‰¹é‡ç®¡é“è™•ç†å®Œæˆ. æˆåŠŸ: {stats['completed_steps']}/{stats['total_steps']} ({success_rate:.1f}%)",
            "pipeline_state": self.pipeline_state,
            "step_outputs": self.pipeline_state["step_outputs"],
            "processing_stats": stats,
            "final_working_dir": current_working_dir  # æœ€çµ‚çš„å·¥ä½œç›®éŒ„
        }
        
        self.logger.info(f"[PipelineOrchestrator] ğŸ‰ {final_result['message']}")
        self.logger.info(f"[PipelineOrchestrator] ğŸ“‚ æœ€çµ‚è¼¸å‡ºç›®éŒ„: {current_working_dir}")
        
        return final_result