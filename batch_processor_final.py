#!/usr/bin/env python3
"""
WaifuC å¢å¼·ç‰ˆæ‰¹è™•ç†å™¨
é›†æˆæ‰€æœ‰AIåœ–ç‰‡è™•ç†åŠŸèƒ½
"""

import os
import sys
import argparse
import logging
from pathlib import Path

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def setup_argument_parser():
    """è¨­ç½®å‘½ä»¤è¡Œåƒæ•¸è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description='WaifuC å¢å¼·ç‰ˆAIåœ–ç‰‡æ‰¹è™•ç†å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  # åŸºæœ¬æ‰¹è™•ç† (æ‰€æœ‰åŠŸèƒ½)
  python batch_processor_enhanced.py input_images/ output_images/

  # åªé€²è¡Œäººè‡‰åµæ¸¬åˆ†é¡
  python batch_processor_enhanced.py input_images/ output_images/ --only-face-detection

  # åªé€²è¡Œé‡è¤‡åœ–ç‰‡æ·˜æ±°
  python batch_processor_enhanced.py input_images/ output_images/ --only-clustering

  # åªé€²è¡Œåœ–ç‰‡è£åˆ‡
  python batch_processor_enhanced.py input_images/ output_images/ --only-crop

  # åªé€²è¡Œåœ–ç‰‡æ¨™è¨˜
  python batch_processor_enhanced.py input_images/ output_images/ --only-tagging

  # åªé€²è¡Œåœ–ç‰‡æ”¾å¤§
  python batch_processor_enhanced.py input_images/ output_images/ --only-upscale

  # è‡ªå®šç¾©è™•ç†æµç¨‹
  python batch_processor_enhanced.py input_images/ output_images/ \
    --steps validate,face_detect,tag,upscale

æ–°å¢åŠŸèƒ½èªªæ˜:
  ğŸ“‹ åœ–ç‰‡é©—è­‰: æª¢æŸ¥åœ–ç‰‡å®Œæ•´æ€§ï¼Œè‡ªå‹•éš”é›¢æå£æ–‡ä»¶
  ğŸ‘¥ äººè‡‰åˆ†é¡: æŒ‰äººè‡‰æ•¸é‡è‡ªå‹•åˆ†é¡ (ç„¡è‡‰/å–®è‡‰/é›™è‡‰/å¤šè‡‰)
  ğŸ”„ æ™ºèƒ½å»é‡: ä½¿ç”¨LPIPSç®—æ³•æ·˜æ±°é‡è¤‡åœ–ç‰‡ï¼Œä¿ç•™æœ€ä½³å“è³ª
  âœ‚ï¸  æ™ºèƒ½è£åˆ‡: è‡ªå‹•æª¢æ¸¬ä¸¦è£åˆ‡é ­éƒ¨/ä¸ŠåŠèº«/å…¨èº«ï¼Œåˆ†é¡å­˜å„²
  ğŸ·ï¸  è‡ªå‹•æ¨™è¨˜: ä½¿ç”¨WD14æ¨¡å‹ç”Ÿæˆç²¾ç¢ºæ¨™ç±¤ï¼Œæ”¯æŒæ‰¹é‡ä¿å­˜
  ğŸ” æ™ºèƒ½æ”¾å¤§: AIæ”¾å¤§åˆ°æŒ‡å®šå°ºå¯¸ï¼Œé©åˆæ¨¡å‹è¨“ç·´ä½¿ç”¨
        """)
    
    parser.add_argument('input_dir', help='è¼¸å…¥åœ–ç‰‡ç›®éŒ„')
    parser.add_argument('output_dir', help='è¼¸å‡ºç›®éŒ„')
    
    # è™•ç†æ¨¡å¼é¸é …
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument('--only-validation', action='store_true',
                           help='åªåŸ·è¡Œåœ–ç‰‡é©—è­‰')
    mode_group.add_argument('--only-face-detection', action='store_true',
                           help='åªåŸ·è¡Œäººè‡‰åµæ¸¬åˆ†é¡')
    mode_group.add_argument('--only-clustering', action='store_true',
                           help='åªåŸ·è¡ŒLPIPSèšé¡å»é‡')
    mode_group.add_argument('--only-crop', action='store_true',
                           help='åªåŸ·è¡Œåœ–ç‰‡è£åˆ‡')
    mode_group.add_argument('--only-tagging', action='store_true',
                           help='åªåŸ·è¡Œåœ–ç‰‡æ¨™è¨˜')
    mode_group.add_argument('--only-upscale', action='store_true',
                           help='åªåŸ·è¡Œåœ–ç‰‡æ”¾å¤§')
    
    # è‡ªå®šç¾©æ­¥é©Ÿ
    parser.add_argument('--steps', type=str,
                       help='è‡ªå®šç¾©è™•ç†æ­¥é©Ÿ (ç”¨é€—è™Ÿåˆ†éš”): validate,face_detect,cluster,crop,tag,upscale')
    
    # é…ç½®é¸é …
    parser.add_argument('--face-threshold', type=float, default=0.3,
                       help='äººè‡‰åµæ¸¬é–¾å€¼ (é»˜èª: 0.3)')
    parser.add_argument('--target-face-count', type=int, default=1,
                       help='è¨“ç·´éœ€è¦çš„äººè‡‰æ•¸é‡ (é»˜èª: 1, -1=ä¸é™åˆ¶)')
    parser.add_argument('--face-filter-mode', choices=['keep_target', 'exclude_target', 'classify_all'],
                       default='keep_target', help='äººè‡‰éæ¿¾æ¨¡å¼ (é»˜èª: keep_target)')
    parser.add_argument('--clustering-threshold', type=float, default=0.3,
                       help='èšé¡ç›¸ä¼¼åº¦é–¾å€¼ (é»˜èª: 0.3)')
    parser.add_argument('--upscale-size', type=str, default='2048x2048',
                       help='æ”¾å¤§ç›®æ¨™å°ºå¯¸ (é»˜èª: 2048x2048)')
    parser.add_argument('--tag-threshold', type=float, default=0.35,
                       help='æ¨™ç±¤ç”Ÿæˆé–¾å€¼ (é»˜èª: 0.35)')
    
    # è¼¸å‡ºæ§åˆ¶
    parser.add_argument('--preserve-structure', action='store_true',
                       help='ä¿æŒåŸå§‹ç›®éŒ„çµæ§‹')
    parser.add_argument('--recursive', action='store_true', default=True,
                       help='éæ­¸è™•ç†å­ç›®éŒ„ (é»˜èªé–‹å•Ÿ)')
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       default='INFO', help='æ—¥èªŒç´šåˆ¥')
    
    return parser

def main():
    """ä¸»å‡½æ•¸"""
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    # æª¢æŸ¥è¼¸å…¥ç›®éŒ„
    if not os.path.isdir(args.input_dir):
        print(f"âŒ éŒ¯èª¤: è¼¸å…¥ç›®éŒ„ä¸å­˜åœ¨: {args.input_dir}")
        return 1
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("ğŸš€ WaifuC å¢å¼·ç‰ˆæ‰¹è™•ç†å™¨å•Ÿå‹•")
    print("=" * 60)
    print(f"ğŸ“ è¼¸å…¥ç›®éŒ„: {args.input_dir}")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {args.output_dir}")
    
    # ç¢ºå®šè™•ç†æ­¥é©Ÿ
    if args.steps:
        selected_steps = [s.strip() for s in args.steps.split(',')]
    elif args.only_validation:
        selected_steps = ['validate']
    elif args.only_face_detection:
        selected_steps = ['face_detect']
    elif args.only_clustering:
        selected_steps = ['cluster']
    elif args.only_crop:
        selected_steps = ['crop']
    elif args.only_tagging:
        selected_steps = ['tag']
    elif args.only_upscale:
        selected_steps = ['upscale']
    else:
        selected_steps = ['validate', 'face_detect', 'cluster', 'crop', 'tag', 'upscale']
    
    print(f"ğŸ”§ è™•ç†æ­¥é©Ÿ: {', '.join(selected_steps)}")
    
    # é¡¯ç¤ºäººè‡‰åµæ¸¬é…ç½®ï¼ˆå¦‚æœåŒ…å«æ­¤æ­¥é©Ÿï¼‰
    if 'face_detect' in selected_steps:
        print(f"ğŸ‘¥ ç›®æ¨™äººè‡‰æ•¸é‡: {args.target_face_count}")
        print(f"ğŸ‘¥ éæ¿¾æ¨¡å¼: {args.face_filter_mode}")
    
    print("=" * 60)
    
    try:
        # å°å…¥å¿…è¦æ¨¡å¡Š (å¦‚æœå¯ç”¨)
        print("ğŸ“¦ æ­£åœ¨è¼‰å…¥è™•ç†æ¨¡å¡Š...")
        
# å˜—è©¦å°å…¥æ™ºèƒ½ç·¨æ’å™¨
        try:
            from core.pipeline_orchestrator import PipelineOrchestrator
            from config import settings
            from utils.logger_config import setup_logging
            
            print("âœ… æ‰€æœ‰æ¨¡å¡Šè¼‰å…¥æˆåŠŸ")
            print("\nğŸ¯ é–‹å§‹æ™ºèƒ½ç®¡é“è™•ç†...")
            
            # è¨­ç½®æ—¥èªŒ
            logger = setup_logging("pipeline", "logs/", args.log_level)
            
            # æ‡‰ç”¨å‘½ä»¤è¡Œåƒæ•¸åˆ°é…ç½®
            if hasattr(settings, 'FACE_DETECTION_TARGET_FACE_COUNT'):
                settings.FACE_DETECTION_TARGET_FACE_COUNT = args.target_face_count
            if hasattr(settings, 'FACE_DETECTION_FILTER_MODE'):
                settings.FACE_DETECTION_FILTER_MODE = args.face_filter_mode
            if hasattr(settings, 'FACE_DETECTION_CONFIDENCE_THRESHOLD'):
                settings.FACE_DETECTION_CONFIDENCE_THRESHOLD = args.face_threshold
            
            # å‰µå»ºæ™ºèƒ½ç·¨æ’å™¨
            orchestrator = PipelineOrchestrator(config=settings, logger=logger)
            
            # åŸ·è¡Œè™•ç†ç®¡é“
            result = orchestrator.process_pipeline(args.input_dir, selected_steps)
            
            if result["success"]:
                print("\nâœ¨ è™•ç†å®Œæˆï¼")
                print(f"\nğŸ“Š {result['message']}")
                
                # é¡¯ç¤ºè©³ç´°çµæœ
                step_outputs = result.get("step_outputs", {})
                for step_name, step_result in step_outputs.items():
                    if step_result.get("success"):
                        print(f"  âœ… {step_name}: {step_result.get('message', '')}")
                    else:
                        print(f"  âŒ {step_name}: {step_result.get('message', '')}")
                
                # ç‰¹åˆ¥é¡¯ç¤ºäººè‡‰åµæ¸¬çµæœ
                if 'face_detect' in step_outputs:
                    face_result = step_outputs['face_detect']
                    if face_result.get("filter_applied"):
                        print(f"\nğŸ‘¥ äººè‡‰éæ¿¾çµæœ:")
                        print(f"  â€¢ è¨“ç·´å¯ç”¨åœ–ç‰‡: {face_result.get('training_count', 0)} å€‹")
                        print(f"  â€¢ æ’é™¤åœ–ç‰‡: {face_result.get('excluded_count', 0)} å€‹")
                        print(f"  â€¢ è¨“ç·´ç›®éŒ„: {face_result.get('training_directory', 'N/A')}")
                
                # é¡¯ç¤ºè£åˆ‡çµæœ
                if 'crop' in step_outputs:
                    crop_result = step_outputs['crop']
                    if crop_result.get("success"):
                        print(f"\nâœ‚ï¸ è£åˆ‡çµæœ:")
                        print(f"  â€¢ æˆåŠŸè£åˆ‡: {crop_result.get('successful_crops', 0)} å€‹")
                        print(f"  â€¢ è£åˆ‡è¼¸å‡º: {crop_result.get('output_directory', 'N/A')}")
                
                print("\nğŸ‰ æ™ºèƒ½ç®¡é“è™•ç†å®Œæˆï¼")
                return 0
            else:
                print(f"\nâŒ è™•ç†å¤±æ•—: {result['message']}")
                return 1
                
        except ImportError:
            print("âš ï¸ ç„¡æ³•è¼‰å…¥å®Œæ•´åŠŸèƒ½æ¨¡å¡Šï¼Œé¡¯ç¤ºåŠŸèƒ½é è¦½...")
            
            # é¡¯ç¤ºæœƒåŸ·è¡Œçš„è™•ç†æµç¨‹
            step_descriptions = {
                'validate': 'ğŸ“‹ åœ–ç‰‡é©—è­‰ - æª¢æŸ¥å®Œæ•´æ€§ä¸¦éš”é›¢ç„¡æ•ˆåœ–ç‰‡',
                'face_detect': f'ğŸ‘¥ äººè‡‰åµæ¸¬ - ä¿ç•™{args.target_face_count}å€‹äººè‡‰çš„åœ–ç‰‡',
                'cluster': 'ğŸ”„ æ™ºèƒ½å»é‡ - ä½¿ç”¨LPIPSæ·˜æ±°é‡è¤‡åœ–ç‰‡',
                'crop': 'âœ‚ï¸ æ™ºèƒ½è£åˆ‡ - å¾éæ¿¾å¾Œçš„åœ–ç‰‡é€²è¡Œè£åˆ‡åˆ†é¡',
                'tag': 'ğŸ·ï¸ è‡ªå‹•æ¨™è¨˜ - ç”Ÿæˆç²¾ç¢ºæ¨™ç±¤ä¸¦ä¿å­˜',
                'upscale': 'ğŸ” æ™ºèƒ½æ”¾å¤§ - AIæ”¾å¤§åˆ°è¨“ç·´å°ºå¯¸'
            }
            
            print("\nğŸ“‹ å°‡åŸ·è¡Œçš„è™•ç†æµç¨‹:")
            for step in selected_steps:
                if step in step_descriptions:
                    print(f"  {step_descriptions[step]}")
            
            if len(selected_steps) > 1:
                print("\nğŸ”— æ‰¹é‡è™•ç†ç®¡é“ (ç›®éŒ„ç´šåˆ¥æ­¥é©Ÿé †åºåŸ·è¡Œ):")
                print("  âœ… æ­£ç¢ºé‚è¼¯: æ¯å€‹æ­¥é©Ÿå®Œæˆæ•´å€‹ç›®éŒ„è™•ç†å¾Œï¼Œå†é€²å…¥ä¸‹ä¸€å€‹æ­¥é©Ÿ")
                print("  âŒ éŒ¯èª¤é‚è¼¯: æ¯å¼µåœ–ç‰‡èµ°å®Œæ•´å€‹ç®¡é“")
                print("\nğŸ“‹ åŸ·è¡Œé †åº:")
                
                current_dir = args.input_dir
                for i, step in enumerate(selected_steps, 1):
                    step_name = {
                        'validate': 'åœ–ç‰‡é©—è­‰',
                        'face_detect': 'äººè‡‰åµæ¸¬èˆ‡éæ¿¾', 
                        'cluster': 'LPIPSèšé¡å»é‡',
                        'crop': 'åœ–ç‰‡è£åˆ‡åˆ†é¡',
                        'tag': 'è‡ªå‹•æ¨™ç±¤ç”Ÿæˆ',
                        'upscale': 'AIåœ–ç‰‡æ”¾å¤§'
                    }.get(step, step)
                    
                    print(f"  {i}. {step_name}: è™•ç†æ•´å€‹ {current_dir} ç›®éŒ„")
                    
                    # é æ¸¬ä¸‹ä¸€å€‹ç›®éŒ„
                    if step == 'face_detect' and args.face_filter_mode in ['keep_target', 'exclude_target']:
                        current_dir = f"{args.input_dir}/training_faces"
                    elif step == 'crop':
                        current_dir = f"{current_dir.rstrip('/')}_parent/cropped_images"
                    elif step == 'upscale':
                        current_dir = f"{current_dir.rstrip('/')}_parent/upscaled_images"
            
            print("\nâœ… åŠŸèƒ½é è¦½å®Œæˆï¼è«‹å®‰è£ä¾è³´ä»¥ä½¿ç”¨å®Œæ•´åŠŸèƒ½ã€‚")
            return 0
        
    except ImportError as e:
        print(f"âŒ æ¨¡å¡Šå°å…¥å¤±æ•—: {e}")
        print("ğŸ’¡ è«‹ç¢ºä¿å·²å®‰è£æ‰€æœ‰ä¾è³´é …ç›®:")
        print("   pip install pillow waifuc[gpu] dghs-imgutils gradio==4.15.0 onnxruntime-gpu==1.21.0")
        return 1
    except Exception as e:
        print(f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
